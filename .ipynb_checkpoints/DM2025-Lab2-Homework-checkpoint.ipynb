{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Student Information**\n",
    "Name: 廖榮健\n",
    "\n",
    "Student ID: 411855165\n",
    "\n",
    "GitHub ID: https://github.com/bryankb10\n",
    "\n",
    "Kaggle name: Bryan Kenneth B.\n",
    "\n",
    "Kaggle private scoreboard snapshot: \n",
    "\n",
    "![pic_ranking.png](./pics/result_screenshot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Instructions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this lab we have divided the assignments into **three phases/parts**. The `first two phases` refer to the `exercises inside the Master notebooks` of the [DM2025-Lab2-Exercise Repo](https://github.com/difersalest/DM2025-Lab2-Exercise.git). The `third phase` refers to an `internal Kaggle competition` that we are gonna run among all the Data Mining students. Together they add up to `100 points` of your grade. There are also some `bonus points` to be gained if you complete `extra exercises` in the lab **(bonus 15 pts)** and in the `Kaggle Competition report` **(bonus 5 pts)**.\n",
    "\n",
    "**Environment recommendations to solve lab 2:**\n",
    "- **Phase 1 exercises:** Need GPU for training the models explained in that part, if you don't have a GPU in your laptop it is recommended to run in Colab or Kaggle for a faster experience, although with CPU they can still be solved but with a slower execution.\n",
    "- **Phase 2 exercises:** We use Gemini's API so everything can be run with only CPU without a problem.\n",
    "- **Phase 3 exercises:** For the competition you will probably need GPU to train your models, so it is recommended to use Colab or Kaggle if you don't have a laptop with a dedicated GPU.\n",
    "- **Optional Ollama Notebook (not graded):** You need GPU, at least 4GB of VRAM with 16 GB of RAM to run the local open-source LLM models. \n",
    "\n",
    "## **Phase 1 (30 pts):**\n",
    "\n",
    "1. __Main Exercises (25 pts):__ Do the **take home exercises** from Sections: `1. Data Preparation` to `9. High-dimension Visualization: t-SNE and UMAP`, in the [DM2025-Lab2-Master-Phase_1 Notebook](https://github.com/difersalest/DM2025-Lab2-Exercise/blob/main/DM2025-Lab2-Master-Phase_1.ipynb). Total: `8 exercises`. Commit your code and submit the repository link to NTU Cool **`BEFORE the deadline (Nov. 3th, 11:59 pm, Monday)`**\n",
    "\n",
    "2. **Code Comments (5 pts):** **Tidy up the code in your notebook**. \n",
    "\n",
    "## **Phase 2 (30 pts):**\n",
    "\n",
    "1. **Main Exercises (25 pts):** Do the remaining **take home exercises** from Section: `2. Large Language Models (LLMs)` in the [DM2025-Lab2-Master-Phase_2_Main Notebook](https://github.com/difersalest/DM2025-Lab2-Exercise/blob/main/DM2025-Lab2-Master-Phase_2_Main.ipynb). Total: `5 exercises required from sections 2.1, 2.2, 2.4 and 2.6`. Commit your code and submit the repository link to NTU Cool **`BEFORE the deadline (Nov. 24th, 11:59 pm, Monday)`**\n",
    "\n",
    "2. **Code Comments (5 pts):** **Tidy up the code in your notebook**. \n",
    "\n",
    "3. **`Bonus (15 pts):`** Complete the bonus exercises in the [DM2025-Lab2-Master-Phase_2_Bonus Notebook](https://github.com/difersalest/DM2025-Lab2-Exercise/blob/main/DM2025-Lab2-Master-Phase_2_Bonus.ipynb) and [DM2025-Lab2-Master-Phase_2_Main Notebook](https://github.com/difersalest/DM2025-Lab2-Exercise/blob/main/DM2025-Lab2-Master-Phase_2_Main.ipynb) `where 2 exercises are counted as bonus from sections 2.3 and 2.5 in the main notebook`. Total: `7 exercises`. Commit your code and submit the repository link to NTU Cool **`BEFORE the deadline (Nov. 24th, 11:59 pm, Monday)`**\n",
    "\n",
    "## **Phase 3 (40 pts):**\n",
    "\n",
    "1. **Kaggle Competition Participation (30 pts):** Participate in the in-class **Kaggle Competition** regarding Emotion Recognition on Twitter by clicking in this link: **[Data Mining Class Kaggle Competition](https://www.kaggle.com/t/3a2df4c6d6b4417e8bf718ed648d7554)**. The scoring will be given according to your place in the Private Leaderboard ranking: \n",
    "    - **Bottom 40%**: Get 20 pts of the 30 pts in this competition participation part.\n",
    "\n",
    "    - **Top 41% - 100%**: Get (0.6N + 1 - x) / (0.6N) * 10 + 20 points, where N is the total number of participants, and x is your rank. (ie. If there are 100 participants and you rank 3rd your score will be (0.6 * 100 + 1 - 3) / (0.6 * 100) * 10 + 20 = 29.67% out of 30%.)   \n",
    "    Submit your last submission **`BEFORE the deadline (Nov. 24th, 11:59 pm, Monday)`**. Make sure to take a screenshot of your position at the end of the competition and store it as `pic_ranking.png` under the `pics` folder of this repository and rerun the cell **Student Information**.\n",
    "\n",
    "2. **Competition Report (10 pts)** A report section to be filled in inside this notebook in Markdown Format, we already provided you with the template below. You need to describe your work developing the model for the competition. The report should include a section describing briefly the following elements: \n",
    "* Your preprocessing steps.\n",
    "* The feature engineering steps.\n",
    "* Explanation of your model.\n",
    "\n",
    "* **`Bonus (5 pts):`**\n",
    "    * You will have to describe more detail in the previous steps.\n",
    "    * Mention different things you tried.\n",
    "    * Mention insights you gained. \n",
    "\n",
    "[Markdown Guide - Basic Syntax](https://www.markdownguide.org/basic-syntax/)\n",
    "\n",
    "**`Things to note for Phase 3:`**\n",
    "\n",
    "* **The code used for the competition should be in this Jupyter Notebook File** `DM2025-Lab2-Homework.ipynb`.\n",
    "\n",
    "* **Push the code used for the competition to your repository**.\n",
    "\n",
    "* **The code should have a clear separation for the same sections of the report, preprocessing, feature engineering and model explanation. Briefly comment your code for easier understanding, we provide a template at the end of this notebook.**\n",
    "\n",
    "* Showing the kaggle screenshot of the ranking plus the code in this notebook will ensure the validity of your participation and the report to obtain the corresponding points.\n",
    "\n",
    "After the competition ends you will have two days more to submit the `DM2025-Lab2-Homework.ipynb` with your report in markdown format and your code. Do everything **`BEFORE the deadline (Nov. 26th, 11:59 pm, Wednesday) to obtain 100% of the available points.`**\n",
    "\n",
    "Upload your files to your repository then submit the link to it on the corresponding NTU Cool assignment.\n",
    "\n",
    "## **Deadlines:**\n",
    "\n",
    "![lab2_deadlines](./pics/lab2_deadlines.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Next you will find the template report with some simple markdown syntax explanations, use it to structure your content.\n",
    "\n",
    "You can delete the syntax suggestions after you use them.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "# **Project Report**\n",
    "\n",
    "**Syntax:** `#` creates the largest heading (H1).\n",
    "\n",
    "---\n",
    "**Syntax:** `---` creates a horizontal rule (a separator line).\n",
    "\n",
    "## 1. Model Development (10 pts Required)\n",
    "\n",
    "**Syntax:** `##` creates a secondary heading (H2).\n",
    "\n",
    "**Describe briefly each section, you can add graphs/charts to support your explanations.**\n",
    "\n",
    "### 1.1 Preprocessing Steps\n",
    "\n",
    "**Syntax:** `###` creates a tertiary heading (H3).\n",
    "\n",
    "[Content for Preprocessing]\n",
    "\n",
    "**Example Syntax for Content:**\n",
    "*   **Bold text:** `**text**`\n",
    "*   *Italic text*: `*text*`\n",
    "*   Bullet point list:\n",
    "    * Item 1\n",
    "    * Item 2\n",
    "\n",
    "Markdown Syntax to Add Image: `![Description of the Image](./your_local_folder/name_of_the_image.png)`\n",
    "\n",
    "![Example Markdown Syntax to Add Image](./pics/example_md_img.png)\n",
    "\n",
    "### 1.2 Feature Engineering Steps\n",
    "\n",
    "[Content for Feature Engineering]\n",
    "\n",
    "### 1.3 Explanation of Your Model\n",
    "\n",
    "[Content for Model Explanation]\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Bonus Section (5 pts Optional)\n",
    "\n",
    "**Add more detail in previous sections**\n",
    "\n",
    "### 2.1 Mention Different Things You Tried\n",
    "\n",
    "[Content for Experiments]\n",
    "\n",
    "### 2.2 Mention Insights You Gained\n",
    "\n",
    "[Content for Insights]\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Project Report** ##\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Preprocessing** ###\n",
    "\n",
    "1. Create df_data for the data_identification.csv and df_emotion for emotoin_csv\n",
    "2. Merge both dataframe  based on their 'id' into a new dataframe called df_full\n",
    "3. Import the final_posts.json into a dataframe called df_post and rename the 'post_id' feature into 'id'\n",
    "4. Merge the initial df_full with df_post based on their 'id' into the new df_full\n",
    "5. Drop the hashtag feature because too many null values\n",
    "![pic_ranking.png](./pics/null_hashtag.png)\n",
    "6. Create a new feature called clean_text which contains the result of text cleaning of the text feature. The text cleaning processes are as follows:\n",
    "   * URL removal: using regex to remove patterns like http..., https..., www...\n",
    "   * Whitespace normalization: replacing multiple spaces/newlines with a single space.\n",
    "   * String normalization / standardization: ensuring the text is in a uniform format.\n",
    "![pic_ranking.png](./pics/text_cleaning.png)\n",
    "7. Split the data into df_train and df_test based on training or testing set\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Feature Engineering** ###\n",
    "\n",
    "My feature engineering process involves creating LLM embeddings using text-embedding-004 model. The reason i did not use gemini-embedding-1 just like our previous homework is because the data contains many instances, so the model takes around 2 hours for the embedding, and at the end i ran out of quota for using the model. So, i used text-embedding-004 based on the suggestion of Gemini, and the embedding takes only around 20 minutes. The process is as follow:\n",
    "\n",
    "1. Load my Google API key for the model\n",
    "2. Setting up get_embeddings_smart, which takes the lists of clean_text, my API key, the filename that will save the embedding results (to save progress and quota of the API), and the split per batch (setting up the batch size is crucial to prevent timeouts or crash mid-process)\n",
    "3. Inside the get_embeddings_smart function:\n",
    "   * I use tqdm to show the progress of the embedding, and split the embedding based on the batch size.\n",
    "   * The reason there is attempt in range(3) is because I gave the system 3 attempts to retry if the API request fails due to timeout or rate limit\n",
    "     before filling the rest with 0 if error\n",
    "   * Google's API sometimes returns embeddings in list form or embedding in single entry, so the if/elif function checks both possibilities so the\n",
    "     code won't break\n",
    "   * The function then append the list value of the vector and convert them into numpy array\n",
    "   * After labeling the emotions into integers, we split the training into training and validation and generate embedding for each of them to test the\n",
    "     F1 score, which will be saved in .npy file, because .npy files cane be read faster than json and csv.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Model Implementation** ###\n",
    "For model implementation, I used linearSVC. LinearSVC is a linear Support Vector Machine classifier that finds a hyperplane in high-dimensional space to separate classes with the largest possible margin. In this project, text-embedding-004 already encode semantic information, so similar emotions are close together in the vector space. LinearSVC uses a one-vs-rest strategy (For each class, it trains a classifier to separate that class from all other classes and during prediction, the class with the highest score wins) for multi-class classification, training separate hyperplanes for each emotion class and predicting the class with the highest score. Because the embeddings make classes nearly linearly separable, LinearSVC is efficient, accurate, and well-suited for emotion detection without needing complex non-linear models. Moreover, linearSVC trains faster and uses less memory than XGBoost and neural network.\n",
    "\n",
    "This is how I implemented the linearSVC:\n",
    "1. Load the .npy files of the embedding\n",
    "2. Initialize the linearSVC model:\n",
    "   * class_weight='balanced' is to automatically adjusts weights for imbalanced classes.\n",
    "   * 'dual=False is to increase efficiency when number of features is bigger than number of samples.\n",
    "3. Implement the training and validating with the model (the result of the macro F1 score is 0.4715 and the weighted F1 score is 0.6266)\n",
    "4. After confirming the model has a good enough score, I trained the model again with the full df_train dataframe without splitting and creating a\n",
    "   validation data and use the training result to the testing dataframe\n",
    "5. Finally, I convert the result of the emotion back to string and import the result to .csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Different Methods** ##\n",
    "I have tried using LLM embeddings with XGBoost because it is the machine learning model I am most familiar with. But the model is too heavy, so i reduced the n_estimators and the max_depth, but the result is not high, only 0.42 F1 score. I also tried TF-IDF and MultinomialNB but it only reaches 0.38 F1 score. Finally, I tried to use logistic regression, which works well with high-dimensional dense vectors, unlike XGBoost. However, the F1 score is 0.44 F1 score. Finally, I asked Gemini for suggestion, and they proposed LinearSVC, something I am not familiar, but I tried it anyway."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Insights** ##\n",
    "From this project, I learned a new ML model called linearSVC. Although I am still not as familiar as other models, it is still interesting to learn this new model, an I am planning to learn more about even SVC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`From here on starts the code section for the competition.`**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Competition Code**\n",
    "\n",
    "## 1. Preprocessing Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Add the code related to the preprocessing steps in cells inside this section\n",
    "import pandas as pd\n",
    "\n",
    "df_data = pd.read_csv(\"data_identification.csv\")\n",
    "df_emotion = pd.read_csv(\"emotion.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x61fc95</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x35663e</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0xc78afe</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x90089c</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0xaba820</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64166</th>\n",
       "      <td>0x4afbe1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64167</th>\n",
       "      <td>0xf5ba78</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64168</th>\n",
       "      <td>0x8f758e</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64169</th>\n",
       "      <td>0xb5a35a</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64170</th>\n",
       "      <td>0x3a9174</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64171 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  split\n",
       "0      0x61fc95   test\n",
       "1      0x35663e  train\n",
       "2      0xc78afe  train\n",
       "3      0x90089c  train\n",
       "4      0xaba820   test\n",
       "...         ...    ...\n",
       "64166  0x4afbe1  train\n",
       "64167  0xf5ba78  train\n",
       "64168  0x8f758e   test\n",
       "64169  0xb5a35a  train\n",
       "64170  0x3a9174   test\n",
       "\n",
       "[64171 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x35663e</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0xc78afe</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x90089c</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x2ffb63</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x989146</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47885</th>\n",
       "      <td>0xd740f2</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47886</th>\n",
       "      <td>0x99267e</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47887</th>\n",
       "      <td>0x4afbe1</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47888</th>\n",
       "      <td>0xf5ba78</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47889</th>\n",
       "      <td>0xb5a35a</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47890 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  emotion\n",
       "0      0x35663e      joy\n",
       "1      0xc78afe     fear\n",
       "2      0x90089c      joy\n",
       "3      0x2ffb63      joy\n",
       "4      0x989146      joy\n",
       "...         ...      ...\n",
       "47885  0xd740f2      joy\n",
       "47886  0x99267e    anger\n",
       "47887  0x4afbe1    anger\n",
       "47888  0xf5ba78      joy\n",
       "47889  0xb5a35a  sadness\n",
       "\n",
       "[47890 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = df_data.merge(df_emotion, on='id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>split</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x61fc95</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x35663e</td>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0xc78afe</td>\n",
       "      <td>train</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x90089c</td>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0xaba820</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64166</th>\n",
       "      <td>0x4afbe1</td>\n",
       "      <td>train</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64167</th>\n",
       "      <td>0xf5ba78</td>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64168</th>\n",
       "      <td>0x8f758e</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64169</th>\n",
       "      <td>0xb5a35a</td>\n",
       "      <td>train</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64170</th>\n",
       "      <td>0x3a9174</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64171 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  split  emotion\n",
       "0      0x61fc95   test      NaN\n",
       "1      0x35663e  train      joy\n",
       "2      0xc78afe  train     fear\n",
       "3      0x90089c  train      joy\n",
       "4      0xaba820   test      NaN\n",
       "...         ...    ...      ...\n",
       "64166  0x4afbe1  train    anger\n",
       "64167  0xf5ba78  train      joy\n",
       "64168  0x8f758e   test      NaN\n",
       "64169  0xb5a35a  train  sadness\n",
       "64170  0x3a9174   test      NaN\n",
       "\n",
       "[64171 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>split</th>\n",
       "      <th>emotion</th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x61fc95</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>We got the ranch, loaded our guns and sat up t...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x35663e</td>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "      <td>I bet there is an army of married couples who ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0xc78afe</td>\n",
       "      <td>train</td>\n",
       "      <td>fear</td>\n",
       "      <td>This could only end badly.</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x90089c</td>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "      <td>My sister squeezed a lime in her milk when she...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0xaba820</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>and that got my head bobbing a little bit.</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64166</th>\n",
       "      <td>0x4afbe1</td>\n",
       "      <td>train</td>\n",
       "      <td>anger</td>\n",
       "      <td>Guilty Gear actually did that before with Guil...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64167</th>\n",
       "      <td>0xf5ba78</td>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "      <td>One of my favorite episodes.</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64168</th>\n",
       "      <td>0x8f758e</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I got my first raspberry from a crowd surfer f...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64169</th>\n",
       "      <td>0xb5a35a</td>\n",
       "      <td>train</td>\n",
       "      <td>sadness</td>\n",
       "      <td>Texans and Astros both shut out tonight. Houst...</td>\n",
       "      <td>[texans, astros, sadness, losers]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64170</th>\n",
       "      <td>0x3a9174</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pre-prepare direction plays hale and hearty si...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64171 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  split  emotion  \\\n",
       "0      0x61fc95   test      NaN   \n",
       "1      0x35663e  train      joy   \n",
       "2      0xc78afe  train     fear   \n",
       "3      0x90089c  train      joy   \n",
       "4      0xaba820   test      NaN   \n",
       "...         ...    ...      ...   \n",
       "64166  0x4afbe1  train    anger   \n",
       "64167  0xf5ba78  train      joy   \n",
       "64168  0x8f758e   test      NaN   \n",
       "64169  0xb5a35a  train  sadness   \n",
       "64170  0x3a9174   test      NaN   \n",
       "\n",
       "                                                    text  \\\n",
       "0      We got the ranch, loaded our guns and sat up t...   \n",
       "1      I bet there is an army of married couples who ...   \n",
       "2                             This could only end badly.   \n",
       "3      My sister squeezed a lime in her milk when she...   \n",
       "4             and that got my head bobbing a little bit.   \n",
       "...                                                  ...   \n",
       "64166  Guilty Gear actually did that before with Guil...   \n",
       "64167                       One of my favorite episodes.   \n",
       "64168  I got my first raspberry from a crowd surfer f...   \n",
       "64169  Texans and Astros both shut out tonight. Houst...   \n",
       "64170  Pre-prepare direction plays hale and hearty si...   \n",
       "\n",
       "                                hashtags  \n",
       "0                                     []  \n",
       "1                                     []  \n",
       "2                                     []  \n",
       "3                                     []  \n",
       "4                                     []  \n",
       "...                                  ...  \n",
       "64166                                 []  \n",
       "64167                                 []  \n",
       "64168                                 []  \n",
       "64169  [texans, astros, sadness, losers]  \n",
       "64170                                 []  \n",
       "\n",
       "[64171 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(\"final_posts.json\", \"r\", encoding=\"UTF-8\") as f:\n",
    "    raw_final_post = json.load(f)\n",
    "\n",
    "final_post = []\n",
    "for post in raw_final_post:\n",
    "    final_post.append(post['root']['_source']['post'])\n",
    "\n",
    "df_post = pd.DataFrame(final_post)\n",
    "if 'post_id' in df_post:\n",
    "    df_post = df_post.rename(columns={'post_id':'id'})\n",
    "\n",
    "df_full = df_full.merge(df_post, on='id', how='left')\n",
    "\n",
    "df_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x61fc95</td>\n",
       "      <td>We got the ranch, loaded our guns and sat up t...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x35663e</td>\n",
       "      <td>I bet there is an army of married couples who ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0xc78afe</td>\n",
       "      <td>This could only end badly.</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x90089c</td>\n",
       "      <td>My sister squeezed a lime in her milk when she...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0xaba820</td>\n",
       "      <td>and that got my head bobbing a little bit.</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64166</th>\n",
       "      <td>0x4afbe1</td>\n",
       "      <td>Guilty Gear actually did that before with Guil...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64167</th>\n",
       "      <td>0xf5ba78</td>\n",
       "      <td>One of my favorite episodes.</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64168</th>\n",
       "      <td>0x8f758e</td>\n",
       "      <td>I got my first raspberry from a crowd surfer f...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64169</th>\n",
       "      <td>0xb5a35a</td>\n",
       "      <td>Texans and Astros both shut out tonight. Houst...</td>\n",
       "      <td>[texans, astros, sadness, losers]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64170</th>\n",
       "      <td>0x3a9174</td>\n",
       "      <td>Pre-prepare direction plays hale and hearty si...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64171 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                               text  \\\n",
       "0      0x61fc95  We got the ranch, loaded our guns and sat up t...   \n",
       "1      0x35663e  I bet there is an army of married couples who ...   \n",
       "2      0xc78afe                         This could only end badly.   \n",
       "3      0x90089c  My sister squeezed a lime in her milk when she...   \n",
       "4      0xaba820         and that got my head bobbing a little bit.   \n",
       "...         ...                                                ...   \n",
       "64166  0x4afbe1  Guilty Gear actually did that before with Guil...   \n",
       "64167  0xf5ba78                       One of my favorite episodes.   \n",
       "64168  0x8f758e  I got my first raspberry from a crowd surfer f...   \n",
       "64169  0xb5a35a  Texans and Astros both shut out tonight. Houst...   \n",
       "64170  0x3a9174  Pre-prepare direction plays hale and hearty si...   \n",
       "\n",
       "                                hashtags  \n",
       "0                                     []  \n",
       "1                                     []  \n",
       "2                                     []  \n",
       "3                                     []  \n",
       "4                                     []  \n",
       "...                                  ...  \n",
       "64166                                 []  \n",
       "64167                                 []  \n",
       "64168                                 []  \n",
       "64169  [texans, astros, sadness, losers]  \n",
       "64170                                 []  \n",
       "\n",
       "[64171 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60623"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full['hashtags'].apply(lambda x: x == []).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.drop('hashtags', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>split</th>\n",
       "      <th>emotion</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x61fc95</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>We got the ranch, loaded our guns and sat up t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x35663e</td>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "      <td>I bet there is an army of married couples who ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0xc78afe</td>\n",
       "      <td>train</td>\n",
       "      <td>fear</td>\n",
       "      <td>This could only end badly.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x90089c</td>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "      <td>My sister squeezed a lime in her milk when she...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0xaba820</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>and that got my head bobbing a little bit.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64166</th>\n",
       "      <td>0x4afbe1</td>\n",
       "      <td>train</td>\n",
       "      <td>anger</td>\n",
       "      <td>Guilty Gear actually did that before with Guil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64167</th>\n",
       "      <td>0xf5ba78</td>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "      <td>One of my favorite episodes.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64168</th>\n",
       "      <td>0x8f758e</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I got my first raspberry from a crowd surfer f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64169</th>\n",
       "      <td>0xb5a35a</td>\n",
       "      <td>train</td>\n",
       "      <td>sadness</td>\n",
       "      <td>Texans and Astros both shut out tonight. Houst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64170</th>\n",
       "      <td>0x3a9174</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pre-prepare direction plays hale and hearty si...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64171 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  split  emotion  \\\n",
       "0      0x61fc95   test      NaN   \n",
       "1      0x35663e  train      joy   \n",
       "2      0xc78afe  train     fear   \n",
       "3      0x90089c  train      joy   \n",
       "4      0xaba820   test      NaN   \n",
       "...         ...    ...      ...   \n",
       "64166  0x4afbe1  train    anger   \n",
       "64167  0xf5ba78  train      joy   \n",
       "64168  0x8f758e   test      NaN   \n",
       "64169  0xb5a35a  train  sadness   \n",
       "64170  0x3a9174   test      NaN   \n",
       "\n",
       "                                                    text  \n",
       "0      We got the ranch, loaded our guns and sat up t...  \n",
       "1      I bet there is an army of married couples who ...  \n",
       "2                             This could only end badly.  \n",
       "3      My sister squeezed a lime in her milk when she...  \n",
       "4             and that got my head bobbing a little bit.  \n",
       "...                                                  ...  \n",
       "64166  Guilty Gear actually did that before with Guil...  \n",
       "64167                       One of my favorite episodes.  \n",
       "64168  I got my first raspberry from a crowd surfer f...  \n",
       "64169  Texans and Astros both shut out tonight. Houst...  \n",
       "64170  Pre-prepare direction plays hale and hearty si...  \n",
       "\n",
       "[64171 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text_col(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    \n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "df_full['clean_text'] = df_full['text'].apply(clean_text_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>split</th>\n",
       "      <th>emotion</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x61fc95</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>We got the ranch, loaded our guns and sat up t...</td>\n",
       "      <td>We got the ranch, loaded our guns and sat up t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x35663e</td>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "      <td>I bet there is an army of married couples who ...</td>\n",
       "      <td>I bet there is an army of married couples who ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0xc78afe</td>\n",
       "      <td>train</td>\n",
       "      <td>fear</td>\n",
       "      <td>This could only end badly.</td>\n",
       "      <td>This could only end badly.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x90089c</td>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "      <td>My sister squeezed a lime in her milk when she...</td>\n",
       "      <td>My sister squeezed a lime in her milk when she...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0xaba820</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>and that got my head bobbing a little bit.</td>\n",
       "      <td>and that got my head bobbing a little bit.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64166</th>\n",
       "      <td>0x4afbe1</td>\n",
       "      <td>train</td>\n",
       "      <td>anger</td>\n",
       "      <td>Guilty Gear actually did that before with Guil...</td>\n",
       "      <td>Guilty Gear actually did that before with Guil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64167</th>\n",
       "      <td>0xf5ba78</td>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "      <td>One of my favorite episodes.</td>\n",
       "      <td>One of my favorite episodes.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64168</th>\n",
       "      <td>0x8f758e</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I got my first raspberry from a crowd surfer f...</td>\n",
       "      <td>I got my first raspberry from a crowd surfer f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64169</th>\n",
       "      <td>0xb5a35a</td>\n",
       "      <td>train</td>\n",
       "      <td>sadness</td>\n",
       "      <td>Texans and Astros both shut out tonight. Houst...</td>\n",
       "      <td>Texans and Astros both shut out tonight. Houst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64170</th>\n",
       "      <td>0x3a9174</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pre-prepare direction plays hale and hearty si...</td>\n",
       "      <td>Pre-prepare direction plays hale and hearty si...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64171 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  split  emotion  \\\n",
       "0      0x61fc95   test      NaN   \n",
       "1      0x35663e  train      joy   \n",
       "2      0xc78afe  train     fear   \n",
       "3      0x90089c  train      joy   \n",
       "4      0xaba820   test      NaN   \n",
       "...         ...    ...      ...   \n",
       "64166  0x4afbe1  train    anger   \n",
       "64167  0xf5ba78  train      joy   \n",
       "64168  0x8f758e   test      NaN   \n",
       "64169  0xb5a35a  train  sadness   \n",
       "64170  0x3a9174   test      NaN   \n",
       "\n",
       "                                                    text  \\\n",
       "0      We got the ranch, loaded our guns and sat up t...   \n",
       "1      I bet there is an army of married couples who ...   \n",
       "2                             This could only end badly.   \n",
       "3      My sister squeezed a lime in her milk when she...   \n",
       "4             and that got my head bobbing a little bit.   \n",
       "...                                                  ...   \n",
       "64166  Guilty Gear actually did that before with Guil...   \n",
       "64167                       One of my favorite episodes.   \n",
       "64168  I got my first raspberry from a crowd surfer f...   \n",
       "64169  Texans and Astros both shut out tonight. Houst...   \n",
       "64170  Pre-prepare direction plays hale and hearty si...   \n",
       "\n",
       "                                              clean_text  \n",
       "0      We got the ranch, loaded our guns and sat up t...  \n",
       "1      I bet there is an army of married couples who ...  \n",
       "2                             This could only end badly.  \n",
       "3      My sister squeezed a lime in her milk when she...  \n",
       "4             and that got my head bobbing a little bit.  \n",
       "...                                                  ...  \n",
       "64166  Guilty Gear actually did that before with Guil...  \n",
       "64167                       One of my favorite episodes.  \n",
       "64168  I got my first raspberry from a crowd surfer f...  \n",
       "64169  Texans and Astros both shut out tonight. Houst...  \n",
       "64170  Pre-prepare direction plays hale and hearty si...  \n",
       "\n",
       "[64171 rows x 5 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train = df_full[df_full['split'] == 'train'].copy()\n",
    "df_test = df_full[df_full['split'] == 'test'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>split</th>\n",
       "      <th>emotion</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x35663e</td>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "      <td>I bet there is an army of married couples who ...</td>\n",
       "      <td>I bet there is an army of married couples who ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0xc78afe</td>\n",
       "      <td>train</td>\n",
       "      <td>fear</td>\n",
       "      <td>This could only end badly.</td>\n",
       "      <td>This could only end badly.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x90089c</td>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "      <td>My sister squeezed a lime in her milk when she...</td>\n",
       "      <td>My sister squeezed a lime in her milk when she...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0x2ffb63</td>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "      <td>Thank you so much❤️</td>\n",
       "      <td>Thank you so much❤️</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0x989146</td>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "      <td>Stinks because ive been in this program for a ...</td>\n",
       "      <td>Stinks because ive been in this program for a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64164</th>\n",
       "      <td>0xd740f2</td>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "      <td>why is everybody seem sp serious?</td>\n",
       "      <td>why is everybody seem sp serious?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64165</th>\n",
       "      <td>0x99267e</td>\n",
       "      <td>train</td>\n",
       "      <td>anger</td>\n",
       "      <td>You can cross fuck off, its 10f all winter in ...</td>\n",
       "      <td>You can cross fuck off, its 10f all winter in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64166</th>\n",
       "      <td>0x4afbe1</td>\n",
       "      <td>train</td>\n",
       "      <td>anger</td>\n",
       "      <td>Guilty Gear actually did that before with Guil...</td>\n",
       "      <td>Guilty Gear actually did that before with Guil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64167</th>\n",
       "      <td>0xf5ba78</td>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "      <td>One of my favorite episodes.</td>\n",
       "      <td>One of my favorite episodes.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64169</th>\n",
       "      <td>0xb5a35a</td>\n",
       "      <td>train</td>\n",
       "      <td>sadness</td>\n",
       "      <td>Texans and Astros both shut out tonight. Houst...</td>\n",
       "      <td>Texans and Astros both shut out tonight. Houst...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47890 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  split  emotion  \\\n",
       "1      0x35663e  train      joy   \n",
       "2      0xc78afe  train     fear   \n",
       "3      0x90089c  train      joy   \n",
       "7      0x2ffb63  train      joy   \n",
       "9      0x989146  train      joy   \n",
       "...         ...    ...      ...   \n",
       "64164  0xd740f2  train      joy   \n",
       "64165  0x99267e  train    anger   \n",
       "64166  0x4afbe1  train    anger   \n",
       "64167  0xf5ba78  train      joy   \n",
       "64169  0xb5a35a  train  sadness   \n",
       "\n",
       "                                                    text  \\\n",
       "1      I bet there is an army of married couples who ...   \n",
       "2                             This could only end badly.   \n",
       "3      My sister squeezed a lime in her milk when she...   \n",
       "7                                    Thank you so much❤️   \n",
       "9      Stinks because ive been in this program for a ...   \n",
       "...                                                  ...   \n",
       "64164                  why is everybody seem sp serious?   \n",
       "64165  You can cross fuck off, its 10f all winter in ...   \n",
       "64166  Guilty Gear actually did that before with Guil...   \n",
       "64167                       One of my favorite episodes.   \n",
       "64169  Texans and Astros both shut out tonight. Houst...   \n",
       "\n",
       "                                              clean_text  \n",
       "1      I bet there is an army of married couples who ...  \n",
       "2                             This could only end badly.  \n",
       "3      My sister squeezed a lime in her milk when she...  \n",
       "7                                    Thank you so much❤️  \n",
       "9      Stinks because ive been in this program for a ...  \n",
       "...                                                  ...  \n",
       "64164                  why is everybody seem sp serious?  \n",
       "64165  You can cross fuck off, its 10f all winter in ...  \n",
       "64166  Guilty Gear actually did that before with Guil...  \n",
       "64167                       One of my favorite episodes.  \n",
       "64169  Texans and Astros both shut out tonight. Houst...  \n",
       "\n",
       "[47890 rows x 5 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>split</th>\n",
       "      <th>emotion</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x61fc95</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>We got the ranch, loaded our guns and sat up t...</td>\n",
       "      <td>We got the ranch, loaded our guns and sat up t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0xaba820</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>and that got my head bobbing a little bit.</td>\n",
       "      <td>and that got my head bobbing a little bit.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0x66e44d</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Same. Glad it's not just out store.</td>\n",
       "      <td>Same. Glad it's not just out store.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0xc03cf5</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Like always i will wait and see thanks for the...</td>\n",
       "      <td>Like always i will wait and see thanks for the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0x02f65a</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>There's a bit of room between \"not loving sub-...</td>\n",
       "      <td>There's a bit of room between \"not loving sub-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64146</th>\n",
       "      <td>0x0f273c</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>We all do it sometimes don't worry.</td>\n",
       "      <td>We all do it sometimes don't worry.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64150</th>\n",
       "      <td>0xfc4c5d</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>This New Year I visited more relatives than us...</td>\n",
       "      <td>This New Year I visited more relatives than us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64157</th>\n",
       "      <td>0xb318a3</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>R u a dad or did ur dad leave u both have bad ...</td>\n",
       "      <td>R u a dad or did ur dad leave u both have bad ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64168</th>\n",
       "      <td>0x8f758e</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I got my first raspberry from a crowd surfer f...</td>\n",
       "      <td>I got my first raspberry from a crowd surfer f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64170</th>\n",
       "      <td>0x3a9174</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pre-prepare direction plays hale and hearty si...</td>\n",
       "      <td>Pre-prepare direction plays hale and hearty si...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16281 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id split emotion  \\\n",
       "0      0x61fc95  test     NaN   \n",
       "4      0xaba820  test     NaN   \n",
       "5      0x66e44d  test     NaN   \n",
       "6      0xc03cf5  test     NaN   \n",
       "8      0x02f65a  test     NaN   \n",
       "...         ...   ...     ...   \n",
       "64146  0x0f273c  test     NaN   \n",
       "64150  0xfc4c5d  test     NaN   \n",
       "64157  0xb318a3  test     NaN   \n",
       "64168  0x8f758e  test     NaN   \n",
       "64170  0x3a9174  test     NaN   \n",
       "\n",
       "                                                    text  \\\n",
       "0      We got the ranch, loaded our guns and sat up t...   \n",
       "4             and that got my head bobbing a little bit.   \n",
       "5                    Same. Glad it's not just out store.   \n",
       "6      Like always i will wait and see thanks for the...   \n",
       "8      There's a bit of room between \"not loving sub-...   \n",
       "...                                                  ...   \n",
       "64146                We all do it sometimes don't worry.   \n",
       "64150  This New Year I visited more relatives than us...   \n",
       "64157  R u a dad or did ur dad leave u both have bad ...   \n",
       "64168  I got my first raspberry from a crowd surfer f...   \n",
       "64170  Pre-prepare direction plays hale and hearty si...   \n",
       "\n",
       "                                              clean_text  \n",
       "0      We got the ranch, loaded our guns and sat up t...  \n",
       "4             and that got my head bobbing a little bit.  \n",
       "5                    Same. Glad it's not just out store.  \n",
       "6      Like always i will wait and see thanks for the...  \n",
       "8      There's a bit of room between \"not loving sub-...  \n",
       "...                                                  ...  \n",
       "64146                We all do it sometimes don't worry.  \n",
       "64150  This New Year I visited more relatives than us...  \n",
       "64157  R u a dad or did ur dad leave u both have bad ...  \n",
       "64168  I got my first raspberry from a crowd surfer f...  \n",
       "64170  Pre-prepare direction plays hale and hearty si...  \n",
       "\n",
       "[16281 rows x 5 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Phase 1: Embeddings\n",
      "Generating embeddings via API for 38312 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding Batches:  99%|████████████████████████████████████████████████████████████▌| 762/767 [18:57<00:11,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 38100 error: Server disconnected without sending a response.. Retrying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding Batches: 100%|█████████████████████████████████████████████████████████████| 767/767 [19:28<00:00,  1.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings via API for 9578 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding Batches: 100%|█████████████████████████████████████████████████████████████| 192/192 [04:22<00:00,  1.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings via API for 16281 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding Batches: 100%|█████████████████████████████████████████████████████████████| 326/326 [06:41<00:00,  1.23s/it]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "from google import genai\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "env_path = \"./config/.env\"\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "client = genai.Client(api_key=api_key)\n",
    "\n",
    "def get_embeddings_smart(texts, client, filename, batch_size=50):\n",
    "    print(f\"Generating embeddings via API for {len(texts)} texts...\")\n",
    "    embeddings = []\n",
    "    \n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=\"Embedding Batches\"):\n",
    "        batch_texts = texts[i : i + batch_size]\n",
    "        \n",
    "        for attempt in range(3):\n",
    "            try:\n",
    "                result = client.models.embed_content(\n",
    "                    model=\"models/text-embedding-004\",\n",
    "                    contents=batch_texts\n",
    "                )\n",
    "                \n",
    "                if hasattr(result, 'embeddings'):\n",
    "                    embedding_list = result.embeddings\n",
    "                elif hasattr(result, 'embedding'):\n",
    "                    embedding_list = result.embedding\n",
    "                else:\n",
    "                    raise AttributeError(\"Response has neither 'embedding' nor 'embeddings'\")\n",
    "                \n",
    "                batch_embeddings = []\n",
    "                for emb_obj in embedding_list:\n",
    "                    batch_embeddings.append(list(emb_obj.values))\n",
    "                embeddings.extend(batch_embeddings)\n",
    "\n",
    "                time.sleep(0.5)\n",
    "                break\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Batch {i} error: {e}. Retrying...\")\n",
    "                time.sleep(1.0)\n",
    "        else:\n",
    "            print(f\"Failed batch {i}. Filling with zeros.\")\n",
    "            embeddings.extend([[0.0] * 768 for _ in range(len(batch_texts))])\n",
    "    \n",
    "    embeddings_array = np.array(embeddings, dtype=np.float32)\n",
    "    \n",
    "    np.save(filename, embeddings_array)\n",
    "    return embeddings_array \n",
    "\n",
    "le = LabelEncoder()\n",
    "y_full_encoded = le.fit_transform(df_train['emotion'])\n",
    "\n",
    "X_train_text, X_val_text, y_train_enc, y_val_enc = train_test_split(\n",
    "    df_train['clean_text'].tolist(), \n",
    "    y_full_encoded,\n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y_full_encoded\n",
    ")\n",
    "\n",
    "X_test_text = df_test['clean_text'].tolist()\n",
    "\n",
    "print(\"\\n>>> Phase 1: Embeddings\")\n",
    "X_train_emb = get_embeddings_smart(X_train_text, client, \"X_train_emb.npy\")\n",
    "X_val_emb   = get_embeddings_smart(X_val_text,   client, \"X_val_emb.npy\")\n",
    "X_test_emb  = get_embeddings_smart(X_test_text,  client, \"X_test_emb.npy\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Implementation Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Add the code related to the model implementation steps in cells inside this section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cached embeddings...\n",
      "\n",
      "Training LinearSVC...\n",
      "Trained in 46.6 seconds.\n",
      "Macro F1: 0.4715\n",
      "Weighted F1: 0.6266\n",
      "Saved 'submission_linear_svc.csv'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "print(\"Loading cached embeddings...\")\n",
    "X_train_emb = np.load(\"X_train_emb.npy\")\n",
    "X_val_emb = np.load(\"X_val_emb.npy\")\n",
    "X_test_emb = np.load(\"X_test_emb.npy\")\n",
    "\n",
    "print(\"\\nTraining LinearSVC...\")\n",
    "\n",
    "base_svc = LinearSVC(class_weight='balanced', dual=False, random_state=42, max_iter=5000)\n",
    "\n",
    "start = time.time()\n",
    "base_svc.fit(X_train_emb, y_train_enc)  # Train on 80% for validation\n",
    "print(f\"Trained in {time.time() - start:.1f} seconds.\")\n",
    "\n",
    "y_val_pred = base_svc.predict(X_val_emb)\n",
    "val_f1_macro = f1_score(y_val_enc, y_val_pred, average='macro')\n",
    "val_f1_weighted = f1_score(y_val_enc, y_val_pred, average='weighted')\n",
    "\n",
    "print(f\"Macro F1: {val_f1_macro:.4f}\")\n",
    "print(f\"Weighted F1: {val_f1_weighted:.4f}\")\n",
    "\n",
    "X_full = np.concatenate([X_train_emb, X_val_emb])\n",
    "y_full = np.concatenate([y_train_enc, y_val_enc])\n",
    "base_svc.fit(X_full, y_full)\n",
    "\n",
    "test_preds = base_svc.predict(X_test_emb)\n",
    "final_preds = le.inverse_transform(test_preds)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'id': df_test['id'],\n",
    "    'emotion': final_preds\n",
    "})\n",
    "submission.to_csv('submission_linear_svc.csv', index=False)\n",
    "print(\"Saved 'submission_linear_svc.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
